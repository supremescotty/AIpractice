import numpy as np
import tensorflow as tf
from tensorflow.keras.datasets import mnist, emnist
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense

# Load the MNIST dataset for digits
(x_train_digits, y_train_digits), (x_test_digits, y_test_digits) = mnist.load_data()

# Load the EMNIST dataset for letters
(x_train_letters, y_train_letters), (x_test_letters, y_test_letters) = emnist.load_data()

# Combine the datasets
x_train = np.concatenate((x_train_digits, x_train_letters), axis=0)
y_train = np.concatenate((y_train_digits, y_train_letters), axis=0)
x_test = np.concatenate((x_test_digits, x_test_letters), axis=0)
y_test = np.concatenate((y_test_digits, y_test_letters), axis=0)

# Normalize and reshape the input data
x_train = x_train.reshape(-1, 28, 28, 1) / 255.0
x_test = x_test.reshape(-1, 28, 28, 1) / 255.0

# Convert labels to one-hot encoding
num_classes = 36  # 10 digits + 26 letters
y_train = tf.keras.utils.to_categorical(y_train, num_classes)
y_test = tf.keras.utils.to_categorical(y_test, num_classes)

# Create a CNN model
model = Sequential()
model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))
model.add(Flatten())
model.add(Dense(128, activation='relu'))
model.add(Dense(num_classes, activation='softmax'))

# Compile and train the model
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
model.fit(x_train, y_train, epochs=10, batch_size=128, validation_data=(x_test, y_test))

# Evaluate the model on the test set
loss, accuracy = model.evaluate(x_test, y_test)
print("Test Loss: {:.4f}".format(loss))
print("Test Accuracy: {:.2f}%".format(accuracy * 100))
